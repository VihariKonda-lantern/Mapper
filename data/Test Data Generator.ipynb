{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43d73b31-54f1-4a83-a71d-8e2851624e24",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Parameter entry"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Collect Client Name and Client Id\n",
    "\n",
    "dbutils.widgets.removeAll()\n",
    "\n",
    "dbutils.widgets.text(\"client_name\", \"\", \"CDAP Client Name\")\n",
    "# dbutils.widgets.text(\"clientId\", \"\", \"Carehub Client ID\")\n",
    "# dbutils.widgets.text(\"sponsor\", \"\", \"Plan Sponsor\")\n",
    "# dbutils.widgets.text(\"clientCode\", \"\", \"Client Code\")\n",
    "\n",
    "client_name = dbutils.widgets.get(\"client_name\")\n",
    "# clientId = dbutils.widgets.get(\"clientId\")\n",
    "# sponsor = dbutils.widgets.get(\"sponsor\")\n",
    "# ClientCode = dbutils.widgets.get(\"clientCode\")\n",
    "\n",
    "domain = \"PlanSponsorClaims\"\n",
    "nRows = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "988443e9-9efa-416f-8317-62aca3039f55",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set up environment"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import col, date_format, to_date\n",
    "from databricks.sdk.runtime import dbutils\n",
    "import glob\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "current_dir = \"/Workspace/Users/kayley.lutzer@edhc.com/Bug Fixes/data-platform/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32ee68b6-79de-4c8e-bc86-eb9ce70cc1ed",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "SQL Server Auth"
    }
   },
   "outputs": [],
   "source": [
    "sql_server_name = dbutils.secrets.get(scope=\"ETL-KeyVault\", key=\"sql-etl-cdap-server\")\n",
    "sql_server_database = dbutils.secrets.get(scope=\"ETL-KeyVault\", key=\"sql-etl-cdap-db\")\n",
    "sql_server_user_name = dbutils.secrets.get(scope=\"ETL-KeyVault\", key=\"sql-etl-cdap-user\")\n",
    "sql_server_password = dbutils.secrets.get(scope=\"ETL-KeyVault\", key=\"sql-etl-cdap-pwd\")\n",
    "\n",
    "jdbc_url = (f\"jdbc:sqlserver://{sql_server_name}.database.windows.net:1433;\"\n",
    "                f\"database={sql_server_database};\"\n",
    "                f\"user={sql_server_user_name}@{sql_server_name};\"\n",
    "                f\"password={sql_server_password};\"\n",
    "                f\"encrypt=true;trustServerCertificate=false;\"\n",
    "                f\"hostNameInCertificate=*.database.windows.net;loginTimeout=30;\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8da3cf9-62bd-4a15-b256-dcb92cd3c271",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Ingest Config Data"
    }
   },
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "                        select \n",
    "                        ic.IngestionConfigId,d.DomainId,d.DomainName as domain,c.DAPClientName as client \n",
    "                        ,c.ClientKey,ps.PlanSponsorName,pp.PreprocessorName \n",
    "                        ,ipt.GroupName,ipt.SubGroupName \n",
    "                        ,ipt.ParamName,ip.ParamValue\n",
    "                        from CDAP.IngestionConfig ic \n",
    "                        join CDAP.DomainClient dc on (ic.DomainClientId = dc.DomainClientId and dc.isactive=1) \n",
    "                        join CDAP.ClientSponsor cs on (ic.ClientSponsorId = cs.ClientSponsorId and cs.isactive=1) \n",
    "                        join CDAP.DomainSponsor ds on (ic.DomainSponsorId = ds.DomainSponsorId and ds.isactive=1) \n",
    "                        join CDAP.Preprocessor pp on (ic.PreprocessorId = pp.PreprocessorId and pp.isactive=1) \n",
    "                        join CDAP.Domain d on (d.DomainId = dc.DomainId and dc.isactive=1 and d.isactive=1) \n",
    "                        join CDAP.Client c on (c.ClientKey = dc.ClientKey and dc.isactive=1 and c.isactive=1) \n",
    "                        join CDAP.PlanSponsor ps on (ps.PlanSponsorId = cs.PlanSponsorId and cs.isactive=1 and ps.isactive=1) \n",
    "                        join CDAP.IngestionConfigParameter icp on (icp.IngestionConfigId = ic.IngestionConfigId and icp.IsActive=1) \n",
    "                        join CDAP.IngestionParameter ip on (icp.ParameterId = ip.ParameterId and ip.IsActive=1) \n",
    "                        join CDAP.IngestionParameterType ipt on (ip.ParameterTypeId = ipt.ParameterTypeId and ipt.IsActive=1) \n",
    "                        where ic.isactive=1 \n",
    "                        and d.DomainName = (case when '{domain}'='None' then d.DomainName else '{domain}' end)\n",
    "                        and c.DAPClientName = (case when '{client_name}'='None' then c.DAPClientName else '{client_name}' end)\n",
    "                        \"\"\"\n",
    "\n",
    "result_df = spark.read.format(\"jdbc\") \\\n",
    "                .option(\"url\", jdbc_url) \\\n",
    "                .option(\"query\", query) \\\n",
    "                .option(\"user\", sql_server_user_name) \\\n",
    "                .option(\"password\", sql_server_password) \\\n",
    "                .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "                .load()\n",
    "\n",
    "# Convert the DataFrame to a list of dictionaries\n",
    "result = result_df.collect()\n",
    "config_data = {\"domains\":[]}\n",
    "for row in result:\n",
    "    row_dict = row.asDict()\n",
    "    if row_dict.get(\"domain\") not in config_data[\"domains\"]:\n",
    "        config_data[\"domains\"].append(row_dict.get(\"domain\"))\n",
    "    if row_dict.get(\"GroupName\") not in config_data.keys():\n",
    "        config_data[row_dict.get(\"GroupName\")] = {}\n",
    "    if row_dict.get(\"domain\") not in config_data[row_dict.get(\"GroupName\")].keys():\n",
    "        config_data[row_dict.get(\"GroupName\")][row_dict.get(\"domain\")] = {}\n",
    "    if row_dict.get(\"client\") not in config_data[row_dict.get(\"GroupName\")][row_dict.get(\"domain\")].keys():\n",
    "        config_data[row_dict.get(\"GroupName\")][row_dict.get(\"domain\")][row_dict.get(\"client\")] = {}\n",
    "        config_data[row_dict.get(\"GroupName\")][row_dict.get(\"domain\")][row_dict.get(\"client\")][\"ingestion_config_id\"] = row_dict.get(\"IngestionConfigId\")\n",
    "        config_data[row_dict.get(\"GroupName\")][row_dict.get(\"domain\")][row_dict.get(\"client\")][\"domain_id\"] = row_dict.get(\"DomainId\")\n",
    "        config_data[row_dict.get(\"GroupName\")][row_dict.get(\"domain\")][row_dict.get(\"client\")][\"domain\"] = row_dict.get(\"domain\")\n",
    "        config_data[row_dict.get(\"GroupName\")][row_dict.get(\"domain\")][row_dict.get(\"client\")][\"client_id\"] = row_dict.get(\"ClientKey\")\n",
    "        config_data[row_dict.get(\"GroupName\")][row_dict.get(\"domain\")][row_dict.get(\"client\")][\"client\"] = row_dict.get(\"client\")\n",
    "        config_data[row_dict.get(\"GroupName\")][row_dict.get(\"domain\")][row_dict.get(\"client\")][\"plan_sponsor_name\"] = row_dict.get(\"PlanSponsorName\")\n",
    "    if row_dict.get(\"SubGroupName\") is not None and len(row_dict.get(\"SubGroupName\")) > 0:\n",
    "        if row_dict.get(\"SubGroupName\") not in config_data[row_dict.get(\"GroupName\")][row_dict.get(\"domain\")][row_dict.get(\"client\")].keys():\n",
    "            config_data[row_dict.get(\"GroupName\")][row_dict.get(\"domain\")][row_dict.get(\"client\")][row_dict.get(\"SubGroupName\")] = {}\n",
    "        config_data[row_dict.get(\"GroupName\")][row_dict.get(\"domain\")][row_dict.get(\"client\")][row_dict.get(\"SubGroupName\")][row_dict.get(\"ParamName\")] = row_dict.get(\"ParamValue\")\n",
    "    else:\n",
    "        config_data[row_dict.get(\"GroupName\")][row_dict.get(\"domain\")][row_dict.get(\"client\")][row_dict.get(\"ParamName\")] = row_dict.get(\"ParamValue\")\n",
    "\n",
    "if config_data['domains'] == []:\n",
    "    dbutils.notebook.exit(\"client doesn't exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d080b990-99b1-42e0-8c41-019f9f26a1f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)\n",
       "File \u001b[0;32m<command-5403996148952337>, line 2\u001b[0m\n",
       "\u001b[1;32m      1\u001b[0m client_carehub_name \u001b[38;5;241m=\u001b[39m config_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain_configurations\u001b[39m\u001b[38;5;124m'\u001b[39m][domain][client_name]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
       "\u001b[0;32m----> 2\u001b[0m clientId \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect ClientId from etl_dev.dev_structured.lntrninternal_carehub_client_unified where Name = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_carehub_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcollect()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mClientId\n",
       "\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(clientId)\n",
       "\n",
       "\u001b[0;31mIndexError\u001b[0m: list index out of range"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "IndexError",
        "evalue": "list index out of range"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>IndexError</span>: list index out of range"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "File \u001b[0;32m<command-5403996148952337>, line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m client_carehub_name \u001b[38;5;241m=\u001b[39m config_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain_configurations\u001b[39m\u001b[38;5;124m'\u001b[39m][domain][client_name]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m clientId \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect ClientId from etl_dev.dev_structured.lntrninternal_carehub_client_unified where Name = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_carehub_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcollect()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mClientId\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(clientId)\n",
        "\u001b[0;31mIndexError\u001b[0m: list index out of range"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "client_carehub_name = config_data['domain_configurations'][domain][client_name].get('client_name')\n",
    "clientId = spark.sql(f\"select ClientId from etl_dev.dev_structured.lntrninternal_carehub_client_unified where Name = '{client_carehub_name}'\").collect()[0].ClientId\n",
    "print(clientId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bf4f6cc-a60f-423e-b439-f61faa57a221",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Process config values"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)\n",
       "File \u001b[0;32m<command-5403996148952337>, line 2\u001b[0m\n",
       "\u001b[1;32m      1\u001b[0m client_carehub_name \u001b[38;5;241m=\u001b[39m config_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain_configurations\u001b[39m\u001b[38;5;124m'\u001b[39m][domain][client_name]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
       "\u001b[0;32m----> 2\u001b[0m clientId \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect ClientId from etl_dev.dev_structured.lntrninternal_carehub_client_unified where Name = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_carehub_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcollect()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mClientId\n",
       "\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(clientId)\n",
       "\n",
       "\u001b[0;31mIndexError\u001b[0m: list index out of range"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {
        "client_name": "Anthem_Global"
       },
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "IndexError",
        "evalue": "list index out of range"
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "File \u001b[0;32m<command-5403996148952337>, line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m client_carehub_name \u001b[38;5;241m=\u001b[39m config_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain_configurations\u001b[39m\u001b[38;5;124m'\u001b[39m][domain][client_name]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m clientId \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect ClientId from etl_dev.dev_structured.lntrninternal_carehub_client_unified where Name = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_carehub_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcollect()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mClientId\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(clientId)\n",
        "\u001b[0;31mIndexError\u001b[0m: list index out of range"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_format = config_data['reading_configurations'][domain][client_name].get('format')\n",
    "sep = config_data['reading_configurations'][domain][client_name]['read_kwargs'].get('sep')\n",
    "date_formats = config_data['mapping_configurations'][domain][client_name].get('dateformat').split(',')\n",
    "file_name_date_format = config_data['domain_configurations'][domain][client_name].get('file_name_date_format')\n",
    "file_name_date_regex_pattern = config_data['domain_configurations'][domain][client_name].get('file_name_date_regex_pattern')\n",
    "include_header = config_data['reading_configurations'][domain][client_name]['read_kwargs'].get('header')\n",
    "if include_header == 'Y':\n",
    "    include_header = True\n",
    "elif include_header == 'N':\n",
    "    include_header = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e83d792f-dfd4-4d59-a565-69d55fd31470",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read in layout"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)\n",
       "File \u001b[0;32m<command-5403996148952337>, line 2\u001b[0m\n",
       "\u001b[1;32m      1\u001b[0m client_carehub_name \u001b[38;5;241m=\u001b[39m config_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain_configurations\u001b[39m\u001b[38;5;124m'\u001b[39m][domain][client_name]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
       "\u001b[0;32m----> 2\u001b[0m clientId \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect ClientId from etl_dev.dev_structured.lntrninternal_carehub_client_unified where Name = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_carehub_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcollect()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mClientId\n",
       "\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(clientId)\n",
       "\n",
       "\u001b[0;31mIndexError\u001b[0m: list index out of range"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {
        "client_name": "Anthem_Global"
       },
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "IndexError",
        "evalue": "list index out of range"
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "File \u001b[0;32m<command-5403996148952337>, line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m client_carehub_name \u001b[38;5;241m=\u001b[39m config_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain_configurations\u001b[39m\u001b[38;5;124m'\u001b[39m][domain][client_name]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m clientId \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect ClientId from etl_dev.dev_structured.lntrninternal_carehub_client_unified where Name = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_carehub_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcollect()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mClientId\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(clientId)\n",
        "\u001b[0;31mIndexError\u001b[0m: list index out of range"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read LAYOUT and collect headers \n",
    "\n",
    "query = f\"\"\"\n",
    "                select TOP 1000 cd.columnname as source_column, tc.columnorder,\n",
    "                (case when cd.datatype='string' then 'varchar' else cd.datatype end) as data_type, \n",
    "                (case when tc.isnullable=1 then 0 else 1 end) as required,\n",
    "                tc.StartPosition as start_position,\n",
    "                tc.EndPosition as end_position\n",
    "                from \n",
    "                cdap.ingestionconfig ic\n",
    "                join cdap.DomainClient dc on (ic.DomainClientId = dc.DomainClientId)\n",
    "                join cdap.DomainSponsor ds on (ic.DomainSponsorId = ds.DomainSponsorId)\n",
    "                join cdap.ClientSponsor cs on (ic.ClientSponsorId = cs.ClientSponsorId)\n",
    "                join cdap.Domain d on (d.domainid = ds.DomainId)\n",
    "                join cdap.Client c on (c.clientkey = dc.ClientKey)\n",
    "                --\n",
    "                join cdap.columnmapping cm on (cm.ingestionconfigid = ic.ingestionconfigid)\n",
    "                join cdap.tablecolumn tc on (tc.tablecolumnid = cm.sourcetablecolumnid)\n",
    "                join cdap.columndetail cd on (tc.columndetailid = cd.columndetailid)\n",
    "                join cdap.zonetable zt on (zt.tableid = tc.tableid)\n",
    "                join cdap.ProcessingZone z on (z.zoneid = zt.zoneid)\n",
    "                -- where z.name = 'prep' and ic.isactive=1 \n",
    "                where z.name = 'raw' and ic.isactive=1 \n",
    "                and d.DomainName = '{domain}'\n",
    "                and c.DAPClientName = '{client_name}'\n",
    "                order by tc.columnorder\n",
    "            \"\"\"\n",
    "# Execute the query using sql_server_operation\n",
    "#source_layout = self.spark.sql(query)\n",
    "layout = spark.read.format(\"jdbc\") \\\n",
    "                .option(\"url\", jdbc_url) \\\n",
    "                .option(\"query\", query) \\\n",
    "                .option(\"user\", sql_server_user_name) \\\n",
    "                .option(\"password\", sql_server_password) \\\n",
    "                .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "                .load()\n",
    "\n",
    "# Convert the DataFrame to a list of dictionaries\n",
    "layout_df = [row.asDict() for row in layout.collect()]\n",
    "layout_has_underscore = layout.filter(layout['source_column'].contains('_')).count() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74d8b414-1977-48c1-88ed-3d487da75fe3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)\n",
       "File \u001b[0;32m<command-5403996148952337>, line 2\u001b[0m\n",
       "\u001b[1;32m      1\u001b[0m client_carehub_name \u001b[38;5;241m=\u001b[39m config_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain_configurations\u001b[39m\u001b[38;5;124m'\u001b[39m][domain][client_name]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
       "\u001b[0;32m----> 2\u001b[0m clientId \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect ClientId from etl_dev.dev_structured.lntrninternal_carehub_client_unified where Name = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_carehub_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcollect()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mClientId\n",
       "\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(clientId)\n",
       "\n",
       "\u001b[0;31mIndexError\u001b[0m: list index out of range"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {
        "client_name": "Anthem_Global"
       },
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "IndexError",
        "evalue": "list index out of range"
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "File \u001b[0;32m<command-5403996148952337>, line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m client_carehub_name \u001b[38;5;241m=\u001b[39m config_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain_configurations\u001b[39m\u001b[38;5;124m'\u001b[39m][domain][client_name]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m clientId \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect ClientId from etl_dev.dev_structured.lntrninternal_carehub_client_unified where Name = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_carehub_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcollect()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mClientId\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(clientId)\n",
        "\u001b[0;31mIndexError\u001b[0m: list index out of range"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(layout_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "495e0f1a-f1ac-486c-9668-0d0403f4f367",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read in mapping"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)\n",
       "File \u001b[0;32m<command-5403996148952337>, line 2\u001b[0m\n",
       "\u001b[1;32m      1\u001b[0m client_carehub_name \u001b[38;5;241m=\u001b[39m config_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain_configurations\u001b[39m\u001b[38;5;124m'\u001b[39m][domain][client_name]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
       "\u001b[0;32m----> 2\u001b[0m clientId \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect ClientId from etl_dev.dev_structured.lntrninternal_carehub_client_unified where Name = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_carehub_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcollect()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mClientId\n",
       "\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(clientId)\n",
       "\n",
       "\u001b[0;31mIndexError\u001b[0m: list index out of range"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {
        "client_name": "Anthem_Global"
       },
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "IndexError",
        "evalue": "list index out of range"
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "File \u001b[0;32m<command-5403996148952337>, line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m client_carehub_name \u001b[38;5;241m=\u001b[39m config_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain_configurations\u001b[39m\u001b[38;5;124m'\u001b[39m][domain][client_name]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m clientId \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect ClientId from etl_dev.dev_structured.lntrninternal_carehub_client_unified where Name = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_carehub_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcollect()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mClientId\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(clientId)\n",
        "\u001b[0;31mIndexError\u001b[0m: list index out of range"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "                    select fcd.columnname as source_column_name, tcd.datatype\n",
    "                    , cm.svmrule as value_mapping, tcd.columnname as target_column_name\n",
    "                    from \n",
    "                    cdap.columnmapping cm\n",
    "                    join cdap.tablecolumn ftc on (cm.sourcetablecolumnid = ftc.tablecolumnid and ftc.IsActive=1)\n",
    "                    join cdap.tablecolumn ttc on (cm.targettablecolumnid = ttc.tablecolumnid and ttc.IsActive=1)\n",
    "                    join cdap.columndetail fcd on (ftc.columndetailid = fcd.columndetailid and fcd.IsActive=1)\n",
    "                    join cdap.columndetail tcd on (ttc.columndetailid = tcd.columndetailid and tcd.IsActive=1)\n",
    "                    join cdap.zonetable fzt on (ftc.tableid = fzt.tableid)\n",
    "                    join cdap.zonetable tzt on (ttc.tableid = tzt.tableid)\n",
    "                    join cdap.processingzone fz on (fzt.zoneid = fz.zoneid)\n",
    "                    join cdap.processingzone tz on (tzt.zoneid = tz.zoneid)\n",
    "                    --\n",
    "                    join cdap.ingestionconfig ic on (ic.IngestionConfigId = cm.IngestionConfigId)\n",
    "                    join cdap.DomainClient dc on (ic.DomainClientId = dc.DomainClientId)\n",
    "                    join cdap.DomainSponsor ds on (ic.DomainSponsorId = ds.DomainSponsorId)\n",
    "                    join cdap.ClientSponsor cs on (ic.ClientSponsorId = cs.ClientSponsorId)\n",
    "                    join cdap.Domain d on (d.domainid = ds.DomainId)\n",
    "                    join cdap.Client c on (c.clientkey = dc.ClientKey)\n",
    "                    where \n",
    "                    fz.name='prep' and tz.name='structured'\n",
    "                    and d.DomainName = '{domain}'\n",
    "                    and c.DAPClientName = '{client_name}'\n",
    "            \"\"\"\n",
    "\n",
    "mapping = spark.read.format(\"jdbc\") \\\n",
    "                .option(\"url\", jdbc_url) \\\n",
    "                .option(\"query\", query) \\\n",
    "                .option(\"user\", sql_server_user_name) \\\n",
    "                .option(\"password\", sql_server_password) \\\n",
    "                .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "                .load()\n",
    "\n",
    "mapping_df = mapping.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02a0b887-f97b-459e-b465-ae250d946b34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)\n",
       "File \u001b[0;32m<command-5403996148952337>, line 2\u001b[0m\n",
       "\u001b[1;32m      1\u001b[0m client_carehub_name \u001b[38;5;241m=\u001b[39m config_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain_configurations\u001b[39m\u001b[38;5;124m'\u001b[39m][domain][client_name]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
       "\u001b[0;32m----> 2\u001b[0m clientId \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect ClientId from etl_dev.dev_structured.lntrninternal_carehub_client_unified where Name = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_carehub_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcollect()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mClientId\n",
       "\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(clientId)\n",
       "\n",
       "\u001b[0;31mIndexError\u001b[0m: list index out of range"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {
        "client_name": "Anthem_Global"
       },
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "IndexError",
        "evalue": "list index out of range"
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "File \u001b[0;32m<command-5403996148952337>, line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m client_carehub_name \u001b[38;5;241m=\u001b[39m config_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain_configurations\u001b[39m\u001b[38;5;124m'\u001b[39m][domain][client_name]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m clientId \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect ClientId from etl_dev.dev_structured.lntrninternal_carehub_client_unified where Name = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_carehub_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcollect()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mClientId\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(clientId)\n",
        "\u001b[0;31mIndexError\u001b[0m: list index out of range"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "PYSPARK_TO_PANDAS_DATE_FORMAT = {\n",
    "    \"yyyyMMdd\": \"%Y%m%d\",\n",
    "    \"yyyy-MM-dd\": \"%Y-%m-%d\",\n",
    "    \"yyyy/MM/dd\": \"%Y/%m/%d\",\n",
    "    \"MMddyyyy\": \"%m%d%Y\",\n",
    "    \"MM/dd/yyyy\": \"%m/%d/%Y\",\n",
    "    \"MMddyy\": \"%m%d%y\",\n",
    "    \"MM/dd/yy\": \"%m/%d/%y\",\n",
    "    \"dd-MM-yyyy\": \"%d-%m-%Y\",\n",
    "    \"dd/MM/yyyy\": \"%d/%m/%Y\",\n",
    "    \"ddMMyyyy\": \"%d%m%Y\",\n",
    "    \"ddMMyy\": \"%d%m%y\",\n",
    "    \"dd/MM/yy\": \"%d/%m/%y\",\n",
    "    \"yyyyMM\": \"%Y%m\",\n",
    "    \"MM-yyyy\": \"%m-%Y\",\n",
    "    \"MM/yyyy\": \"%m/%Y\",\n",
    "    \"ddMMMyyyy\": \"%d%b%Y\",\n",
    "    \"MMM dd yyyy\": \"%b %d %Y\",\n",
    "    \"MMddyyyy\": \"%m%d%Y\",\n",
    "    \"dd MMM yyyy\": \"%d %b %Y\",\n",
    "    \"MMM dd yyyy\": \"%b %d %Y\",\n",
    "    \"MMMM dd yyyy\": \"%B %d %Y\",\n",
    "    \"MM/dd/yyyy hh:mm:ss a\": \"%m/%d/%Y %I:%M:%S %p\"\n",
    "}\n",
    "\n",
    "missing_formats = [fmt for fmt in date_formats if fmt not in PYSPARK_TO_PANDAS_DATE_FORMAT]\n",
    "if missing_formats:\n",
    "    dbutils.notebook.exit(f\"ERROR: Missing date format(s) in mapping: {missing_formats}\")\n",
    "\n",
    "pandas_date_formats = [PYSPARK_TO_PANDAS_DATE_FORMAT.get(fmt, None) for fmt in date_formats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "684cb1e3-a6c8-43a8-b18f-d77fceaa7aec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)\n",
       "File \u001b[0;32m<command-5403996148952337>, line 2\u001b[0m\n",
       "\u001b[1;32m      1\u001b[0m client_carehub_name \u001b[38;5;241m=\u001b[39m config_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain_configurations\u001b[39m\u001b[38;5;124m'\u001b[39m][domain][client_name]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
       "\u001b[0;32m----> 2\u001b[0m clientId \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect ClientId from etl_dev.dev_structured.lntrninternal_carehub_client_unified where Name = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_carehub_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcollect()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mClientId\n",
       "\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(clientId)\n",
       "\n",
       "\u001b[0;31mIndexError\u001b[0m: list index out of range"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {
        "client_name": "Anthem_Global"
       },
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "IndexError",
        "evalue": "list index out of range"
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "File \u001b[0;32m<command-5403996148952337>, line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m client_carehub_name \u001b[38;5;241m=\u001b[39m config_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain_configurations\u001b[39m\u001b[38;5;124m'\u001b[39m][domain][client_name]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m clientId \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect ClientId from etl_dev.dev_structured.lntrninternal_carehub_client_unified where Name = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_carehub_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcollect()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mClientId\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(clientId)\n",
        "\u001b[0;31mIndexError\u001b[0m: list index out of range"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "date_columns = [\n",
    "    row['source_column']\n",
    "    for row in layout\n",
    "        .filter(layout['data_type'] == 'date')\n",
    "        .select('source_column')\n",
    "        .collect()\n",
    "]\n",
    "\n",
    "col_dateformats_dict = {}\n",
    "for column in date_columns:\n",
    "    if column == \"file_date\":\n",
    "        continue\n",
    "    dbutils.widgets.text(column, f\"{date_formats[0]}\", f\"{column} date format\")\n",
    "    col_dateformats_dict[column] = dbutils.widgets.get(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38ada8e2-233a-4da7-9e03-c49cbdf46aea",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "STOP HERE FOR DATE FORMATS - RUN ALL BELOW:"
    }
   },
   "outputs": [],
   "source": [
    "# STOP HERE TO CHANGE DATE FORMATS - RUN ALL BELOW\n",
    "for column in date_columns:\n",
    "    col_dateformats_dict[column] = dbutils.widgets.get(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bdc593e-6868-4700-9611-080b6b41dae1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Generate basic sample data"
    }
   },
   "outputs": [],
   "source": [
    "# Generate basic sample data\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Default faker providers by type\n",
    "DEFAULT_TYPE_PROVIDERS = {\n",
    "    \"varchar\": lambda: fake.bothify(text=\"??###\"),\n",
    "    \"date\": lambda: fake.date(pattern=random.choice(pandas_date_formats)),\n",
    "    # Add other types if needed\n",
    "}\n",
    "\n",
    "# Optional: Per-column overrides for realism\n",
    "# COLUMN_OVERRIDES = {\n",
    "#     \"subscriber_ssn\": lambda: fake.ssn(),\n",
    "#     \"members_sex\": lambda: random.choice([\"M\", \"F\"]),\n",
    "#     \"member_first_name\": lambda: fake.first_name(),\n",
    "#     \"member_last_name\": lambda: fake.last_name(),\n",
    "#     \"claim_no\": lambda: fake.uuid4(),\n",
    "# }\n",
    "\n",
    "def get_provider(column, dtype):\n",
    "    # Use column override if present, else fallback to default type provider\n",
    "    return DEFAULT_TYPE_PROVIDERS.get(dtype, lambda: None)\n",
    "\n",
    "def generate_row(schema_rows):\n",
    "    row = {}\n",
    "    for _, row_meta in schema_rows.toPandas().iterrows():\n",
    "        col = row_meta[\"source_column\"]\n",
    "        dtype = row_meta[\"data_type\"]\n",
    "        provider = get_provider(col, dtype)\n",
    "        if dtype == \"date\":\n",
    "            if col in col_dateformats_dict:\n",
    "                fmt = PYSPARK_TO_PANDAS_DATE_FORMAT.get(col_dateformats_dict[col])\n",
    "            else:\n",
    "                fmt = random.choice(pandas_date_formats)\n",
    "            row[col] = fake.date(pattern=fmt)\n",
    "        else:\n",
    "            row[col] = provider()\n",
    "    return row\n",
    "\n",
    "def generate_fake_data(schema_df, n_rows=nRows):\n",
    "    return pd.DataFrame([generate_row(schema_df) for _ in range(n_rows)])\n",
    "\n",
    "df_pandas = generate_fake_data(layout, nRows)\n",
    "# df = spark.createDataFrame(df_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c464f0f-d17d-437b-b4fb-f4970455656b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = f\"select FirstName,LastName,DOB,Gender from etl_dev.dev_structured.lntrninternal_carehub_member_unified where ClientId = '{clientId}' LIMIT {nRows}\"\n",
    "df_carehub = spark.sql(query)\n",
    "# Convert birth date column to specified format\n",
    "source_dob_col = (\n",
    "    mapping\n",
    "    .filter(mapping['target_column_name'] == 'patient_dob')\n",
    "    .select('source_column_name')\n",
    "    .first()['source_column_name']\n",
    ")\n",
    "\n",
    "if layout_has_underscore is False:\n",
    "    source_dob_col = source_dob_col.replace(\"_\", \" \")\n",
    "\n",
    "dob_col_format = dbutils.widgets.get(f\"{source_dob_col}\")\n",
    "\n",
    "# Convert Carehub DOB back to source format\n",
    "df_carehub = df_carehub.withColumn(\n",
    "    \"DOB\",\n",
    "    date_format(\n",
    "        to_date(\"DOB\", 'yyyy-MM-dd'),\n",
    "        dob_col_format\n",
    "    )\n",
    ")\n",
    "\n",
    "df_carehub = df_carehub.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8be4f8c3-a736-40bb-973c-992151aee2d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CAREHUB_MAPPING = {\n",
    "    'patient_first_name': 'FirstName', \n",
    "    'patient_last_name': 'LastName', \n",
    "    'patient_sex': 'Gender', \n",
    "    'patient_dob': 'DOB', \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d91d79b3-1d69-4af8-8b2b-88bf6cd5b7ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "demo_match_cols = [\n",
    "    (row['source_column_name'], row['target_column_name'])\n",
    "    for row in mapping\n",
    "        .filter((mapping['target_column_name'] == 'patient_dob') | (mapping['target_column_name'] == 'patient_sex') | (mapping['target_column_name'] == 'patient_first_name') | (mapping['target_column_name'] == 'patient_last_name'))\n",
    "        .select('source_column_name','target_column_name').collect()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a36f837c-0349-4706-9963-73acde22688b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for target, source in demo_match_cols:\n",
    "    if layout_has_underscore is False:\n",
    "        target = target.replace(\"_\",\" \")\n",
    "    df_pandas[target] = df_carehub[CAREHUB_MAPPING.get(source)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "423f05b1-c169-41d7-868a-f89e90963867",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "reverse_mapping_dict = {}\n",
    "for row in mapping.collect():\n",
    "    col_name = row['source_column_name']\n",
    "    value_mapping_text = row['value_mapping']\n",
    "    if value_mapping_text != \"\":\n",
    "        mapping_dict = {}\n",
    "        for line in value_mapping_text.split(\"\\n\"):\n",
    "            line = line.strip()\n",
    "            if not line or \",\" not in line:\n",
    "                continue\n",
    "            src, repl = line.split(\",\")\n",
    "            if src != \"source_value\":\n",
    "                mapping_dict[repl] = src  # reversed: repl -> src\n",
    "            reverse_mapping_dict[col_name] = mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d32e741-f9bb-4381-837d-8ed81aac21d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "reverse_mapping_dict = {}\n",
    "for row in mapping.collect():\n",
    "    col_name = row['source_column_name']\n",
    "    value_mapping_text = row['value_mapping']\n",
    "    if value_mapping_text != \"\":\n",
    "        mapping_dict = {}\n",
    "        for line in value_mapping_text.split(\"\\n\"):\n",
    "            line = line.replace('\\r', '')  # Remove carriage return\n",
    "            if ',' in line:\n",
    "                src, repl = line.split(\",\", 1)\n",
    "                if src != \"source_value\":\n",
    "                    mapping_dict[repl] = src  # reversed: repl -> src\n",
    "                    reverse_mapping_dict[col_name] = mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b80aa928-33a0-43d0-9751-a90b02378367",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark_df_1 = spark.createDataFrame(df_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52c3935f-3d29-4546-ae12-c0cc61466e31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "for col_name, map_dict in reverse_mapping_dict.items():\n",
    "    # Create UDF for reverse mapping\n",
    "    def reverse_map(val,mapping=map_dict):\n",
    "        return mapping.get(val, val)\n",
    "    reverse_udf = udf(reverse_map, StringType())\n",
    "    if layout_has_underscore is False:\n",
    "        col_name = col_name.replace(\"_\",\" \")\n",
    "    spark_df_1 = spark_df_1.withColumn(col_name, reverse_udf(col(col_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cc6dd9c-af27-44bd-8141-ff14a5fe9e8a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "EXPORT PROCESS"
    }
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "guid = str(uuid.uuid4())[:5]  # generates a 5-digit GUUID\n",
    "\n",
    "formatted_file_date = PYSPARK_TO_PANDAS_DATE_FORMAT.get(file_name_date_format)\n",
    "date_str = datetime.now().strftime(formatted_file_date)\n",
    "file_name = file_name_date_regex_pattern.replace(\"(\\d+)\", date_str).replace(\"$\", \"\")\n",
    "\n",
    "output_dir = f\"abfss://data@edhcdevdl.dfs.core.windows.net/test_data/AUTOGEN{guid}__{file_name}.csv\"\n",
    "final_file = f\"abfss://data@edhcdevdl.dfs.core.windows.net/test_data/AUTOGEN{guid}_{file_name}.csv\"\n",
    "\n",
    "if output_format.lower() in [\"csv\", \"txt\"]:\n",
    "    spark_df_1.coalesce(1).write.format(output_format) \\\n",
    "        .option(\"header\", f\"{include_header}\") \\\n",
    "        .option(\"sep\", sep) \\\n",
    "        .save(output_dir)\n",
    "\n",
    "    files = dbutils.fs.ls(output_dir)\n",
    "    part_file_path = [f.path for f in files if f.name.startswith(\"part-\")][0]\n",
    "\n",
    "    dbutils.fs.cp(part_file_path, final_file)\n",
    "    dbutils.fs.rm(part_file_path)\n",
    "    unwanted_patterns = [\"_SUCCESS\", \"_committed\", \"_started\"]\n",
    "\n",
    "    for f in files:\n",
    "        if any(pattern in f.name for pattern in unwanted_patterns):\n",
    "            dbutils.fs.rm(f.path)\n",
    "    dbutils.fs.rm(output_dir)\n",
    "else:\n",
    "    print(f\"{output_format} is an unsupported file type for the test data generator.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6176541107397826,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Test Data Generator",
   "widgets": {
    "client_name": {
     "currentValue": "Anthem_Global",
     "nuid": "a4ffdfdf-9505-4609-969d-5534176f34fd",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "CDAP Client Name",
      "name": "client_name",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": "CDAP Client Name",
      "name": "client_name",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
